# ğŸš€ ê³ ë„í™”ëœ AI ì—ì´ì „íŠ¸ í…œí”Œë¦¿ (15ê°œ ì´ìƒ ë…¸ë“œ êµ¬ì„±)

ì´ ë¬¸ì„œëŠ” 'SnapShot' ì›Œí¬í”Œë¡œìš° ì†”ë£¨ì…˜ì—ì„œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥í•œ, **15ê°œ ì´ìƒì˜ ë…¸ë“œ**ë¡œ êµ¬ì„±ëœ ë³µí•© ì—ì´ì „íŠ¸ í…œí”Œë¦¿ 10ì¢…ì„ ì •ì˜í•©ë‹ˆë‹¤. ê° í…œí”Œë¦¿ì€ ì‹¤ì „ ë¹„ì¦ˆë‹ˆìŠ¤ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ì„¤ê³„ë˜ì—ˆìœ¼ë©°, ë¶„ê¸°, ë£¨í”„, ì™¸ë¶€ ì—°ë™(Slack, ê²€ìƒ‰)ì„ í¬í•¨í•œ ì •êµí•œ ë¡œì§ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.

---

## 1. ì‹¬ì¸µ ì‹œì¥ ì¡°ì‚¬ ë° ê²½ìŸì‚¬ ë¶„ì„ ì—ì´ì „íŠ¸ (Deep Market Researcher)

### [ì‹œë‚˜ë¦¬ì˜¤]
ì‚¬ìš©ìê°€ íŠ¹ì • ì‚°ì—…ì´ë‚˜ ì œí’ˆêµ°ì„ ì…ë ¥í•˜ë©´, ìµœì‹  ë‰´ìŠ¤, ê¸°ìˆ  ë™í–¥, ì¬ë¬´ ìƒíƒœ, ì†Œë¹„ì ë°˜ì‘ì„ ë‹¤ê°ë„ë¡œ ìˆ˜ì§‘í•˜ê³  ë¶„ì„í•˜ì—¬ ì¢…í•© ë³´ê³ ì„œë¥¼ ì‘ì„±í•©ë‹ˆë‹¤. ê¸´ê¸‰í•œ ì´ìŠˆê°€ ë°œê²¬ë˜ë©´ Slackìœ¼ë¡œ ì¦‰ì‹œ ì•Œë¦¼ì„ ë³´ëƒ…ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start("Start") --> Classify("ë¶„ì„ ëŒ€ìƒ ë¶„ë¥˜ (Classifier)")
    
    Classify -->|Tech| TechSearch1("ê¸°ìˆ  ë‰´ìŠ¤ ê²€ìƒ‰ (Tavily)")
    Classify -->|Finance| FinSearch1("ì¬ë¬´/ì£¼ê°€ ê²€ìƒ‰ (Tavily)")
    Classify -->|Consumer| ReviewSearch1("ì†Œë¹„ì ë¦¬ë·° ê²€ìƒ‰ (Tavily)")
    
    %% Tech Branch
    TechSearch1 --> TechLLM1("ê¸°ìˆ  íŠ¸ë Œë“œ ìš”ì•½ (LLM)")
    TechLLM1 --> TechSearch2("ì£¼ìš” ê²½ìŸ ì œí’ˆ ê²€ìƒ‰ (Tavily)")
    TechSearch2 --> TechLLM2("ìŠ¤í™ ë¹„êµ ë¶„ì„ (LLM)")
    TechLLM2 --> AssignTech("ê¸°ìˆ  ë°ì´í„° ì €ì¥ (Assigner)")
    
    %% Finance Branch
    FinSearch1 --> FinLLM1("ì¬ë¬´ ê±´ì „ì„± ë¶„ì„ (LLM)")
    FinLLM1 --> FinSearch2("ìµœê·¼ ì‹¤ì  ë°œí‘œ ê²€ìƒ‰ (Tavily)")
    FinSearch2 --> FinLLM2("ì„±ì¥ì„± í‰ê°€ (LLM)")
    FinLLM2 --> AssignFin("ì¬ë¬´ ë°ì´í„° ì €ì¥ (Assigner)")
    
    %% Consumer Branch
    ReviewSearch1 --> ReviewLLM1("ê¸/ë¶€ì • ê°ì„± ë¶„ì„ (LLM)")
    ReviewLLM1 --> ReviewSearch2("SNS ë°”ì´ëŸ´ ê²€ìƒ‰ (Tavily)")
    ReviewSearch2 --> ReviewLLM2("ì£¼ìš” ë¶ˆë§Œì‚¬í•­ ì¶”ì¶œ (LLM)")
    ReviewLLM2 --> AssignReview("ë¦¬ë·° ë°ì´í„° ì €ì¥ (Assigner)")
    
    %% Merge
    AssignTech --> MergeLLM("ì¢…í•© ë³´ê³ ì„œ ì‘ì„± (LLM)")
    AssignFin --> MergeLLM
    AssignReview --> MergeLLM
    
    MergeLLM --> RiskCheck("ë¦¬ìŠ¤í¬ ê°ì§€ (If-Else)")
    
    RiskCheck -->|True (High Risk)| SlackAlert("ê¸´ê¸‰ ì•Œë¦¼ ì „ì†¡ (Slack)")
    RiskCheck -->|False (Normal)| AssignLog("ë¡œê·¸ ê¸°ë¡ (Assigner)")
    
    SlackAlert --> EndNode("ì¢…ë£Œ (Answer)")
    AssignLog --> EndNode
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. Classify (Question Classifier)
{
  "model": { "provider": "openai", "name": "gpt-4o" },
  "classes": [
    { "id": "tech", "name": "Technology & Product" },
    { "id": "finance", "name": "Finance & Market" },
    { "id": "consumer", "name": "Consumer Reaction" }
  ],
  "query_template": "Analyze the user's request '{query}' and classify it into the most relevant market research category."
}

// 3. TechSearch1 (Tavily Search)
{
  "query": "{{query}} technology news",
  "topic": "news",
  "search_depth": "advanced",
  "max_results": 5,
  "include_answer": true
}

// 4. TechLLM1 (LLM)
{
  "model": "gpt-4o",
  "temperature": 0.7,
  "prompt_template": "Based on the search results:\n{{TechSearch1.context}}\n\nSummarize the latest technology trends regarding the user's query: {{query}}"
}

// 5. TechSearch2 (Tavily Search)
{
  "query": "Competitors of {{query}} specifications",
  "topic": "general",
  "search_depth": "basic",
  "max_results": 3
}

// 6. TechLLM2 (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Compare the technical specifications of {{query}} with its competitors found in:\n{{TechSearch2.context}}"
}

// 7. AssignTech (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.tech_data",
      "source_variable": "TechLLM2.response"
    }
  ]
}

// 8. FinSearch1 (Tavily Search)
{
  "query": "{{query}} financial report stock price",
  "topic": "finance",
  "search_depth": "advanced",
  "max_results": 5
}

// 9. FinLLM1 (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Analyze financial health based on:\n{{FinSearch1.context}}"
}

// 10. FinSearch2 (Tavily Search)
{
  "query": "{{query}} recent earnings call transcript",
  "topic": "news",
  "search_depth": "basic",
  "max_results": 3
}

// 11. FinLLM2 (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Evaluate growth potential from:\n{{FinSearch2.context}}"
}

// 12. AssignFin (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.fin_data",
      "source_variable": "FinLLM2.response"
    }
  ]
}

// 13. ReviewSearch1 (Tavily Search)
{
  "query": "{{query}} user reviews complaints",
  "topic": "general",
  "search_depth": "advanced",
  "max_results": 10
}

// 14. ReviewLLM1 (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Analyze sentiment (Positive/Negative) from these reviews:\n{{ReviewSearch1.context}}"
}

// 15. ReviewSearch2 (Tavily Search)
{
  "query": "{{query}} viral social media posts",
  "topic": "general",
  "search_depth": "basic"
}

// 16. ReviewLLM2 (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Extract major user complaints and viral topics from:\n{{ReviewSearch2.context}}"
}

// 17. AssignReview (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.review_data",
      "source_variable": "ReviewLLM2.response"
    }
  ]
}

// 18. MergeLLM (LLM)
{
  "model": "claude-3-5-sonnet-20240620",
  "prompt_template": "Combine the following analyses into a comprehensive market report:\n\nTech: {{conversation.tech_data}}\nFinance: {{conversation.fin_data}}\nConsumer: {{conversation.review_data}}\n\nStructure the report with Executive Summary, Detailed Analysis, and Strategic Recommendations. If you detect any critical threats, include the phrase 'CRITICAL RISK' in the summary."
}

// 19. RiskCheck (If-Else)
{
  "cases": [
    {
      "case_id": "high_risk",
      "logical_operator": "and",
      "conditions": [
        {
          "variable_selector": "MergeLLM.response",
          "comparison_operator": "contains",
          "value": "CRITICAL RISK",
          "varType": "string"
        }
      ]
    }
  ]
}

// 20. SlackAlert (Slack)
{
  "channel": "C01234567",
  "use_blocks": true,
  "text": "ğŸš¨ **CRITICAL RISK DETECTED**\n\nA critical risk was found in the market analysis for {{query}}.\n\nSummary:\n{{MergeLLM.response}}"
}

// 21. AssignLog (Assigner)
{
  "operations": [
    {
      "write_mode": "APPEND",
      "input_type": "CONSTANT",
      "target_variable": "conversation.logs",
      "constant_value": "Analysis completed normally."
    }
  ]
}

// 22. EndNode (Answer)
{
  "template": "{{MergeLLM.response}}"
}
```

---

## 2. ë‹¤êµ­ì–´ ì§€ëŠ¥í˜• ê³ ê° ì§€ì› (Global CS Auto-Pilot)

### [ì‹œë‚˜ë¦¬ì˜¤]
ë‹¤êµ­ì–´ ê³ ê° ë¬¸ì˜ë¥¼ ì ‘ìˆ˜ë°›ì•„ ì–¸ì–´ë¥¼ ê°ì§€í•˜ê³ , í•´ë‹¹ ì–¸ì–´ì˜ ì •ì±… ë¬¸ì„œë¥¼ ê²€ìƒ‰(RAG)í•œ ë’¤, ìƒí™©ì— ë§ëŠ” ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤. í™˜ë¶ˆ ë“± ë¯¼ê°í•œ ì£¼ì œëŠ” ê´€ë¦¬ì ìŠ¹ì¸ì„ ìš”ì²­í•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> DetectLang("ì–¸ì–´ ê°ì§€ (LLM)")
    DetectLang --> AssignLang("ì–¸ì–´ ë³€ìˆ˜ ì„¤ì • (Assigner)")
    
    AssignLang --> TranslateQuery("ì˜ì–´ ë²ˆì—­ (LLM)")
    TranslateQuery --> ClassifyIntent("ì˜ë„ ë¶„ë¥˜ (Q-Classifier)")
    
    %% Intent Branches
    ClassifyIntent -->|Refund| KnowledgeRefund("í™˜ë¶ˆ ì •ì±… ê²€ìƒ‰ (Knowledge)")
    ClassifyIntent -->|Technical| KnowledgeTech("ê¸°ìˆ  ë¬¸ì„œ ê²€ìƒ‰ (Knowledge)")
    ClassifyIntent -->|General| KnowledgeGeneral("FAQ ê²€ìƒ‰ (Knowledge)")
    
    %% Refund Process
    KnowledgeRefund --> CheckEligibility("í™˜ë¶ˆ ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨ (If-Else)")
    CheckEligibility -->|Possible| DraftRefund("í™˜ë¶ˆ ì•ˆë‚´ ì´ˆì•ˆ (LLM)")
    CheckEligibility -->|Impossible| DraftReject("ê±°ì ˆ ì•ˆë‚´ ì´ˆì•ˆ (LLM)")
    
    DraftRefund --> SlackAdmin("ê´€ë¦¬ì ìŠ¹ì¸ ìš”ì²­ (Slack)")
    SlackAdmin --> WaitApprove("ìŠ¹ì¸ ëŒ€ê¸° (LLM - Simulation)") 
    %% ì‹¤ì œë¡œëŠ” Human-in-the-loopì´ í•„ìš”í•˜ë‚˜ ì—¬ê¸°ì„  ì‹œë®¬ë ˆì´ì…˜
    
    %% Technical Process
    KnowledgeTech --> SearchGoogle("ì¶”ê°€ í•´ê²°ì±… ê²€ìƒ‰ (Tavily)")
    SearchGoogle --> DraftTechAnswer("ê¸°ìˆ  ë‹µë³€ ì‘ì„± (LLM)")
    
    %% General Process
    KnowledgeGeneral --> DraftGeneral("ì¼ë°˜ ë‹µë³€ ì‘ì„± (LLM)")
    
    %% Merge & Translate Back
    DraftReject --> TranslateBack("ì›ì–´ ë²ˆì—­ (LLM)")
    WaitApprove --> TranslateBack
    DraftTechAnswer --> TranslateBack
    DraftGeneral --> TranslateBack
    
    TranslateBack --> Answer("ìµœì¢… ë‹µë³€ (Answer)")
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. DetectLang (LLM)
{
  "model": "gpt-4o-mini",
  "temperature": 0.0,
  "max_tokens": 10,
  "prompt_template": "Detect the language of this text: '{{query}}'. Return only the ISO 639-1 code (e.g., ko, en, ja, fr). Do not include any other text."
}

// 3. AssignLang (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.language",
      "source_variable": "DetectLang.response"
    }
  ]
}

// 4. TranslateQuery (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Translate the following text to English for internal processing. If it is already English, return it as is.\n\nText: {{query}}"
}

// 5. ClassifyIntent (Question Classifier)
{
  "model": { "provider": "openai", "name": "gpt-4o" },
  "classes": [
    { "id": "refund", "name": "Refund & Billing" },
    { "id": "technical", "name": "Technical Support" },
    { "id": "general", "name": "General Inquiry" }
  ],
  "query_template": "Classify the user intent based on the translated query: '{{TranslateQuery.response}}'"
}

// 6. KnowledgeRefund (Knowledge Retrieval)
{
  "query": "Refund policy and billing rules for: {{TranslateQuery.response}}",
  "k": 4
}

// 7. KnowledgeTech (Knowledge Retrieval)
{
  "query": "Technical troubleshooting guide for: {{TranslateQuery.response}}",
  "k": 4
}

// 8. KnowledgeGeneral (Knowledge Retrieval)
{
  "query": "General FAQ for: {{TranslateQuery.response}}",
  "k": 4
}

// 9. CheckEligibility (If-Else)
{
  "cases": [
    {
      "case_id": "eligible",
      "logical_operator": "or",
      "conditions": [
        {
          "variable_selector": "KnowledgeRefund.context",
          "comparison_operator": "contains",
          "value": "eligible",
          "varType": "string"
        },
        {
          "variable_selector": "KnowledgeRefund.context",
          "comparison_operator": "contains",
          "value": "allow",
          "varType": "string"
        }
      ]
    }
  ]
}

// 10. DraftRefund (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Based on the policy:\n{{KnowledgeRefund.context}}\n\nDraft a refund approval message for the customer. Be polite and professional."
}

// 11. DraftReject (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Based on the policy:\n{{KnowledgeRefund.context}}\n\nDraft a polite refund rejection message explaining why they are not eligible."
}

// 12. SlackAdmin (Slack)
{
  "channel": "#cs-approvals",
  "text": "ğŸ“¢ **Refund Approval Request**\n\nCustomer Query: {{query}}\nProposed Response: {{DraftRefund.response}}\n\nPlease approve or reject.",
  "use_blocks": true
}

// 13. WaitApprove (LLM)
{
  "model": "gpt-3.5-turbo",
  "temperature": 0.0,
  "prompt_template": "Simulate an admin approval. Return exactly: 'Approved. Proceed with the refund process.'"
}

// 14. SearchGoogle (Tavily Search)
{
  "query": "{{TranslateQuery.response}} solution site:stackoverflow.com OR site:github.com",
  "topic": "general",
  "search_depth": "advanced",
  "max_results": 3
}

// 15. DraftTechAnswer (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Combine internal docs and web search results to answer the technical question.\n\nInternal Docs: {{KnowledgeTech.context}}\nWeb Search: {{SearchGoogle.context}}\n\nQuestion: {{TranslateQuery.response}}"
}

// 16. DraftGeneral (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Answer the general inquiry based on the FAQ.\n\nFAQ: {{KnowledgeGeneral.context}}\nQuestion: {{TranslateQuery.response}}"
}

// 17. TranslateBack (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Translate the following response back to the customer's language ({{conversation.language}}).\n\nResponse to translate:\n{{DraftRefund.response}}{{DraftReject.response}}{{WaitApprove.response}}{{DraftTechAnswer.response}}{{DraftGeneral.response}}"
}

// 18. Answer
{
  "template": "{{TranslateBack.response}}"
}
```

---

## 3. ìŠ¤ë§ˆíŠ¸ ë‰´ìŠ¤ë ˆí„° íë ˆì´í„° (News Curator)

### [ì‹œë‚˜ë¦¬ì˜¤]
ì‚¬ìš©ìê°€ ê´€ì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì…ë ¥í•˜ë©´, ê° í‚¤ì›Œë“œë³„ ìµœì‹  ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•˜ê³  ìš”ì•½í•˜ì—¬ ì„¹ì…˜ë³„ë¡œ ì •ë¦¬ëœ ë‰´ìŠ¤ë ˆí„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> ExtractKeywords("í‚¤ì›Œë“œ ì¶”ì¶œ (LLM)")
    ExtractKeywords --> AssignKey1("í‚¤ì›Œë“œ1 í• ë‹¹ (Assigner)")
    ExtractKeywords --> AssignKey2("í‚¤ì›Œë“œ2 í• ë‹¹ (Assigner)")
    ExtractKeywords --> AssignKey3("í‚¤ì›Œë“œ3 í• ë‹¹ (Assigner)")
    
    %% Keyword 1 Process
    AssignKey1 --> SearchK1("í‚¤ì›Œë“œ1 ê²€ìƒ‰ (Tavily)")
    SearchK1 --> SummarizeK1("í‚¤ì›Œë“œ1 ìš”ì•½ (LLM)")
    SummarizeK1 --> StoreK1("ì„¹ì…˜1 ì €ì¥ (Assigner)")
    
    %% Keyword 2 Process
    AssignKey2 --> SearchK2("í‚¤ì›Œë“œ2 ê²€ìƒ‰ (Tavily)")
    SearchK2 --> SummarizeK2("í‚¤ì›Œë“œ2 ìš”ì•½ (LLM)")
    SummarizeK2 --> StoreK2("ì„¹ì…˜2 ì €ì¥ (Assigner)")
    
    %% Keyword 3 Process
    AssignKey3 --> SearchK3("í‚¤ì›Œë“œ3 ê²€ìƒ‰ (Tavily)")
    SearchK3 --> SummarizeK3("í‚¤ì›Œë“œ3 ìš”ì•½ (LLM)")
    SummarizeK3 --> StoreK3("ì„¹ì…˜3 ì €ì¥ (Assigner)")
    
    %% Synthesis
    StoreK3 --> DraftIntro("ì¸íŠ¸ë¡œ ì‘ì„± (LLM)")
    DraftIntro --> DraftOutro("ì•„ì›ƒíŠ¸ë¡œ ì‘ì„± (LLM)")
    
    DraftOutro --> Assemble("ì „ì²´ ì¡°ë¦½ (LLM)")
    Assemble --> FormatCheck("í¬ë§· ê²€ìˆ˜ (If-Else)")
    
    FormatCheck -->|Good| SlackSend("ë‰´ìŠ¤ë ˆí„° ë°œì†¡ (Slack)")
    FormatCheck -->|Bad| Reformat("ì¬í¬ë§·íŒ… (LLM)")
    
    Reformat --> SlackSend
    SlackSend --> Answer
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. ExtractKeywords (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Extract the top 3 most important topics or keywords from the user's request: '{{query}}'.\nReturn the result as a JSON list of strings, e.g., [\"keyword1\", \"keyword2\", \"keyword3\"]. Do not include any other text."
}

// 3. AssignKey1 (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.k1",
      "source_variable": "ExtractKeywords.response[0]"
    }
  ]
}

// 4. AssignKey2 (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.k2",
      "source_variable": "ExtractKeywords.response[1]"
    }
  ]
}

// 5. AssignKey3 (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.k3",
      "source_variable": "ExtractKeywords.response[2]"
    }
  ]
}

// 6. SearchK1 (Tavily Search)
{
  "query": "{{conversation.k1}} news",
  "topic": "news",
  "time_range": "d",
  "max_results": 3
}

// 7. SummarizeK1 (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Summarize these news articles about {{conversation.k1}}:\n{{SearchK1.context}}"
}

// 8. StoreK1 (Assigner)
{
  "operations": [{ "write_mode": "SET", "target_variable": "conversation.section1", "source_variable": "SummarizeK1.response" }]
}

// 9. SearchK2 (Tavily Search)
{
  "query": "{{conversation.k2}} news",
  "topic": "news",
  "time_range": "d",
  "max_results": 3
}

// 10. SummarizeK2 (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Summarize these news articles about {{conversation.k2}}:\n{{SearchK2.context}}"
}

// 11. StoreK2 (Assigner)
{
  "operations": [{ "write_mode": "SET", "target_variable": "conversation.section2", "source_variable": "SummarizeK2.response" }]
}

// 12. SearchK3 (Tavily Search)
{
  "query": "{{conversation.k3}} news",
  "topic": "news",
  "time_range": "d",
  "max_results": 3
}

// 13. SummarizeK3 (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Summarize these news articles about {{conversation.k3}}:\n{{SearchK3.context}}"
}

// 14. StoreK3 (Assigner)
{
  "operations": [{ "write_mode": "SET", "target_variable": "conversation.section3", "source_variable": "SummarizeK3.response" }]
}

// 15. DraftIntro (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Write a catchy introduction for a newsletter covering: {{conversation.k1}}, {{conversation.k2}}, {{conversation.k3}}"
}

// 16. DraftOutro (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Write a concluding remark for the newsletter, wishing the reader a productive week."
}

// 17. Assemble (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "# Weekly Newsletter\n\n{{DraftIntro.response}}\n\n## 1. {{conversation.k1}}\n{{conversation.section1}}\n\n## 2. {{conversation.k2}}\n{{conversation.section2}}\n\n## 3. {{conversation.k3}}\n{{conversation.section3}}\n\n---\n{{DraftOutro.response}}"
}

// 18. FormatCheck (If-Else)
{
  "cases": [
    {
      "case_id": "good_format",
      "logical_operator": "and",
      "conditions": [
        {
          "variable_selector": "Assemble.response",
          "comparison_operator": "contains",
          "value": "## 1.",
          "varType": "string"
        },
        {
          "variable_selector": "Assemble.response",
          "comparison_operator": "contains",
          "value": "## 3.",
          "varType": "string"
        }
      ]
    }
  ]
}

// 19. Reformat (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "The following newsletter is malformed. Please reformat it to strictly follow Markdown structure with headers for each section.\n\n{{Assemble.response}}"
}

// 20. SlackSend (Slack)
{
  "channel": "#daily-brief",
  "text": "{{Assemble.response}}",
  "use_blocks": false
}

// 21. Answer
{
  "template": "Newsletter sent to Slack!\n\nPreview:\n{{Assemble.response}}"
}
```

---

## 4. ì½”ë“œ ë¦¬íŒ©í† ë§ ë° ë³´ì•ˆ ì ê²€ ë´‡ (Code Reviewer)

### [ì‹œë‚˜ë¦¬ì˜¤]
ì…ë ¥ëœ ì½”ë“œ ìŠ¤ë‹ˆí«ì— ëŒ€í•´ êµ¬ì¡°, ë³´ì•ˆ, ì„±ëŠ¥, ìŠ¤íƒ€ì¼ 4ê°€ì§€ ì¸¡ë©´ì„ ë¶„ì„í•˜ê³  ê°œì„ ëœ ì½”ë“œë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> AnalyzeStructure("êµ¬ì¡° ë¶„ì„ (LLM)")
    AnalyzeStructure --> CheckSecurity("ë³´ì•ˆ ì·¨ì•½ì  ì ê²€ (LLM)")
    
    CheckSecurity --> IfSecurityIssue("ë³´ì•ˆ ì´ìŠˆ ì¡´ì¬? (If-Else)")
    IfSecurityIssue -->|Yes| FixSecurity("ë³´ì•ˆ íŒ¨ì¹˜ ìƒì„± (LLM)")
    IfSecurityIssue -->|No| PassSecurity("í†µê³¼ ê¸°ë¡ (Assigner)")
    
    FixSecurity --> CheckPerformance("ì„±ëŠ¥ ë³‘ëª© ì ê²€ (LLM)")
    PassSecurity --> CheckPerformance
    
    CheckPerformance --> IfPerfIssue("ì„±ëŠ¥ ì´ìŠˆ ì¡´ì¬? (If-Else)")
    IfPerfIssue -->|Yes| OptimizePerf("ì„±ëŠ¥ ìµœì í™” (LLM)")
    IfPerfIssue -->|No| PassPerf("í†µê³¼ ê¸°ë¡ (Assigner)")
    
    OptimizePerf --> CheckStyle("ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì ê²€ (LLM)")
    PassPerf --> CheckStyle
    
    CheckStyle --> RefactorCode("ìµœì¢… ë¦¬íŒ©í† ë§ ì½”ë“œ ìƒì„± (LLM)")
    RefactorCode --> GenerateComments("ë¦¬ë·° ì½”ë©˜íŠ¸ ìƒì„± (LLM)")
    
    GenerateComments --> FormatReport("Markdown ë¦¬í¬íŠ¸ ìƒì„± (LLM)")
    FormatReport --> SlackNotify("ê°œë°œì ì•Œë¦¼ (Slack)")
    SlackNotify --> Answer
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. AnalyzeStructure (LLM)
{
  "model": "claude-3-5-sonnet-20240620",
  "prompt_template": "Analyze the architectural structure of the following code. Identify any design pattern violations or poor organization.\n\nCode:\n{{query}}"
}

// 3. CheckSecurity (LLM)
{
  "model": "claude-3-opus-20240229",
  "system_prompt": "You are a senior security engineer. Find vulnerabilities.",
  "prompt_template": "Scan this code for security vulnerabilities (SQL Injection, XSS, sensitive data exposure, etc.). If found, output 'VULNERABILITY FOUND' followed by details. If clean, output 'SECURE'.\n\nCode:\n{{query}}"
}

// 4. IfSecurityIssue (If-Else)
{
  "cases": [
    {
      "case_id": "vuln_found",
      "conditions": [
        {
          "variable_selector": "CheckSecurity.response",
          "comparison_operator": "contains",
          "value": "VULNERABILITY FOUND"
        }
      ]
    }
  ]
}

// 5. FixSecurity (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Apply security patches to the code based on the analysis:\n{{CheckSecurity.response}}\n\nOriginal Code:\n{{query}}"
}

// 6. PassSecurity (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.code_v1",
      "source_variable": "query"
    }
  ]
}

// 7. CheckPerformance (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Analyze the performance of this code. Look for O(n^2) loops, memory leaks, or unoptimized queries. If found, output 'PERFORMANCE ISSUE'.\n\nCode:\n{{FixSecurity.response}}"
}

// 8. IfPerfIssue (If-Else)
{
  "cases": [
    {
      "case_id": "perf_issue",
      "conditions": [
        {
          "variable_selector": "CheckPerformance.response",
          "comparison_operator": "contains",
          "value": "PERFORMANCE ISSUE"
        }
      ]
    }
  ]
}

// 9. OptimizePerf (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Optimize the code for better performance (speed/memory).\n\nCode:\n{{FixSecurity.response}}"
}

// 10. PassPerf (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.code_v2",
      "source_variable": "FixSecurity.response"
    }
  ]
}

// 11. CheckStyle (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Check if the code follows PEP8 (for Python) or standard style guides. Point out indentation or naming errors.\n\nCode:\n{{OptimizePerf.response}}"
}

// 12. RefactorCode (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Apply final refactoring to ensure clean code standards and fix style issues.\n\nCode:\n{{OptimizePerf.response}}"
}

// 13. GenerateComments (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Generate documentation comments (Docstrings) for the refactored code.\n\nCode:\n{{RefactorCode.response}}"
}

// 14. FormatReport (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Create a Markdown review report.\n\n1. Structure Analysis: {{AnalyzeStructure.response}}\n2. Security: {{CheckSecurity.response}}\n3. Performance: {{CheckPerformance.response}}\n4. Final Code:\n```\n{{GenerateComments.response}}\n```"
}

// 15. SlackNotify (Slack)
{
  "channel": "#code-reviews",
  "text": "New Code Review Available.\n\nSummary: {{AnalyzeStructure.response}}\n\nCheck the full report in the dashboard.",
  "use_blocks": false
}

// 16. Answer
{
  "template": "{{FormatReport.response}}"
}
```

---

## 5. ê°œì¸ ë§ì¶¤í˜• ì—¬í–‰ í”Œë˜ë„ˆ (Travel Planner)

### [ì‹œë‚˜ë¦¬ì˜¤]
ëª©ì ì§€ì™€ ê¸°ê°„ì„ ì…ë ¥ë°›ì•„ í•­ê³µê¶Œ, ìˆ™ì†Œ, ë§›ì§‘, ê´€ê´‘ì§€ë¥¼ ê²€ìƒ‰í•˜ê³  ë‚ ì”¨ë¥¼ ê³ ë ¤í•˜ì—¬ ì¼ì •í‘œë¥¼ ì§­ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> ExtractEntities("ëª©ì ì§€/ê¸°ê°„ ì¶”ì¶œ (LLM)")
    ExtractEntities --> GetWeather("í˜„ì§€ ë‚ ì”¨ ê²€ìƒ‰ (Tavily)")
    
    GetWeather --> CheckRain("ë¹„ ì˜ˆë³´ í™•ì¸ (If-Else)")
    
    %% Flight & Hotel
    CheckRain --> SearchFlight("í•­ê³µê¶Œ ê²€ìƒ‰ (Tavily)")
    SearchFlight --> SelectFlight("ìµœì  í•­ê³µê¶Œ ì„ ì • (LLM)")
    SelectFlight --> SearchHotel("í˜¸í…” ê²€ìƒ‰ (Tavily)")
    SearchHotel --> SelectHotel("ìµœì  í˜¸í…” ì„ ì • (LLM)")
    
    %% Activities
    SelectHotel --> SearchSpots("ê´€ê´‘ì§€ ê²€ìƒ‰ (Tavily)")
    SearchSpots --> FilterSpots("ì·¨í–¥ ê¸°ë°˜ í•„í„°ë§ (LLM)")
    
    %% Indoor/Outdoor logic based on rain
    FilterSpots --> IfRainy("ìš°ì²œ ëŒ€ë¹„ (If-Else)")
    IfRainy -->|True| SearchIndoor("ì‹¤ë‚´ í™œë™ ì¶”ê°€ ê²€ìƒ‰ (Tavily)")
    IfRainy -->|False| SearchOutdoor("ì•¼ì™¸ í™œë™ ì¶”ê°€ ê²€ìƒ‰ (Tavily)")
    
    SearchIndoor --> MergeActivities("í™œë™ ëª©ë¡ í†µí•© (Assigner)")
    SearchOutdoor --> MergeActivities
    
    %% Dining
    MergeActivities --> SearchFood("ë§›ì§‘ ê²€ìƒ‰ (Tavily)")
    
    %% Finalize
    SearchFood --> DraftItinerary("ì¼ì •í‘œ ì´ˆì•ˆ ì‘ì„± (LLM)")
    DraftItinerary --> AddTips("ì—¬í–‰ íŒ ì¶”ê°€ (LLM)")
    AddTips --> Answer
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. ExtractEntities (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Extract the 'Destination' and 'Dates' from the user's request: {{query}}. Return as JSON: {\"destination\": \"...\", \"dates\": \"...\"}"
}

// 3. GetWeather (Tavily Search)
{
  "query": "Weather forecast in {{ExtractEntities.response}}",
  "topic": "general",
  "max_results": 3
}

// 4. CheckRain (If-Else)
{
  "cases": [
    {
      "case_id": "rainy",
      "conditions": [{ "variable_selector": "GetWeather.context", "comparison_operator": "contains", "value": "rain" }]
    }
  ]
}

// 5. SearchFlight (Tavily Search)
{
  "query": "Flights to {{ExtractEntities.response}}",
  "topic": "general",
  "max_results": 5
}

// 6. SelectFlight (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Recommend the best flight option based on price and duration:\n{{SearchFlight.context}}"
}

// 7. SearchHotel (Tavily Search)
{
  "query": "Hotels in {{ExtractEntities.response}}",
  "topic": "general",
  "max_results": 5
}

// 8. SelectHotel (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Recommend the top 3 hotels:\n{{SearchHotel.context}}"
}

// 9. SearchSpots (Tavily Search)
{
  "query": "Top tourist attractions in {{ExtractEntities.response}}",
  "topic": "general",
  "max_results": 10
}

// 10. FilterSpots (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Filter these spots based on a 'relaxing' travel style:\n{{SearchSpots.context}}"
}

// 11. IfRainy (If-Else)
{
  "cases": [
    {
      "case_id": "rain_plan",
      "conditions": [{ "variable_selector": "GetWeather.context", "comparison_operator": "contains", "value": "rain" }]
    }
  ]
}

// 12. SearchIndoor (Tavily Search)
{
  "query": "Indoor activities museums malls in {{ExtractEntities.response}}",
  "topic": "general"
}

// 13. SearchOutdoor (Tavily Search)
{
  "query": "Outdoor parks hiking in {{ExtractEntities.response}}",
  "topic": "general"
}

// 14. MergeActivities (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.activities",
      "source_variable": "SearchIndoor.context"
    }
  ]
}

// 15. SearchFood (Tavily Search)
{
  "query": "Best restaurants local food in {{ExtractEntities.response}}",
  "topic": "general"
}

// 16. DraftItinerary (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Create a day-by-day itinerary.\n\nFlights: {{SelectFlight.response}}\nHotels: {{SelectHotel.response}}\nActivities: {{conversation.activities}}\nFood: {{SearchFood.context}}"
}

// 17. AddTips (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Add practical travel tips (transport, safety, packing) for {{ExtractEntities.response}}.\n\nItinerary:\n{{DraftItinerary.response}}"
}

// 18. Answer
{
  "template": "{{AddTips.response}}"
}
```

---

## 6. íˆ¬ì í¬íŠ¸í´ë¦¬ì˜¤ ë¦¬ë°¸ëŸ°ì‹± ì–´ë“œë°”ì´ì € (Investment Advisor)

### [ì‹œë‚˜ë¦¬ì˜¤]
ì‚¬ìš©ìì˜ í˜„ì¬ í¬íŠ¸í´ë¦¬ì˜¤ì™€ ëª©í‘œ ë¹„ì¤‘ì„ ë¹„êµí•˜ì—¬ ë§¤ìˆ˜/ë§¤ë„ ì£¼ë¬¸ì„ ì œì•ˆí•˜ê³  ì‹œì¥ ìƒí™©ì„ ì²´í¬í•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> ParsePortfolio("í¬íŠ¸í´ë¦¬ì˜¤ íŒŒì‹± (LLM)")
    ParsePortfolio --> GetPrices("í˜„ì¬ê°€ ì¡°íšŒ (Tavily)")
    
    GetPrices --> CalcValue("í‰ê°€ê¸ˆì•¡ ê³„ì‚° (LLM)")
    CalcValue --> GetTarget("ëª©í‘œ ë¹„ì¤‘ ë¡œë“œ (Assigner)")
    
    GetTarget --> Compare("ë¹„ì¤‘ ì°¨ì´ ê³„ì‚° (LLM)")
    Compare --> IfRebalance("ë¦¬ë°¸ëŸ°ì‹± í•„ìš”? (If-Else)")
    
    %% Rebalancing Needed
    IfRebalance -->|Yes| CheckMarket("ì‹œì¥ ë‰´ìŠ¤ ì²´í¬ (Tavily)")
    CheckMarket --> AnalyzeSentiment("ì‹œì¥ ì‹¬ë¦¬ ë¶„ì„ (LLM)")
    
    AnalyzeSentiment --> IfCrash("í­ë½ì¥ ì—¬ë¶€ (If-Else)")
    IfCrash -->|Yes| AdjustConservative("ë³´ìˆ˜ì  ì¡°ì • (LLM)")
    IfCrash -->|No| AdjustStandard("í‘œì¤€ ì¡°ì • (LLM)")
    
    AdjustConservative --> DraftOrders("ì£¼ë¬¸ì„œ ìƒì„± (LLM)")
    AdjustStandard --> DraftOrders
    
    DraftOrders --> NotifySlack("íˆ¬ì ì œì•ˆ ë°œì†¡ (Slack)")
    NotifySlack --> Answer
    
    %% No Action
    IfRebalance -->|No| GenHoldReport("ë³´ìœ  ì˜ê²¬ ì‘ì„± (LLM)")
    GenHoldReport --> Answer
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. ParsePortfolio (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Parse the user's portfolio string into JSON.\nInput: {{query}}\nOutput format: {\"AAPL\": 10, \"TSLA\": 5, ...}"
}

// 3. GetPrices (Tavily Search)
{
  "query": "Current stock price of {{ParsePortfolio.response}}",
  "topic": "finance",
  "max_results": 5
}

// 4. CalcValue (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Calculate the total value of the portfolio based on current prices:\nPrices: {{GetPrices.context}}\nHoldings: {{ParsePortfolio.response}}"
}

// 5. GetTarget (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "CONSTANT",
      "target_variable": "conversation.target_ratio",
      "constant_value": "{'AAPL': 0.3, 'TSLA': 0.2, 'MSFT': 0.2, 'GOOGL': 0.3}"
    }
  ]
}

// 6. Compare (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Compare current portfolio ratio vs target ratio. If deviation > 5%, output 'REBALANCE_REQUIRED'.\nCurrent: {{CalcValue.response}}\nTarget: {{conversation.target_ratio}}"
}

// 7. IfRebalance (If-Else)
{
  "cases": [
    {
      "case_id": "rebalance_needed",
      "conditions": [{ "variable_selector": "Compare.response", "comparison_operator": "contains", "value": "REBALANCE_REQUIRED" }]
    }
  ]
}

// 8. CheckMarket (Tavily Search)
{
  "query": "Stock market news today crash recession",
  "topic": "finance",
  "max_results": 5
}

// 9. AnalyzeSentiment (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Analyze market sentiment. If bearish/crash, output 'CRASH_DETECTED'.\nNews: {{CheckMarket.context}}"
}

// 10. IfCrash (If-Else)
{
  "cases": [
    {
      "case_id": "crash_scenario",
      "conditions": [{ "variable_selector": "AnalyzeSentiment.response", "comparison_operator": "contains", "value": "CRASH_DETECTED" }]
    }
  ]
}

// 11. AdjustConservative (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Market is crashing. Suggest a conservative rebalancing plan (increase cash/bonds)."
}

// 12. AdjustStandard (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Market is normal. Suggest standard rebalancing to match target ratios."
}

// 13. DraftOrders (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft precise buy/sell orders based on the plan:\n{{AdjustConservative.response}}{{AdjustStandard.response}}"
}

// 14. NotifySlack (Slack)
{
  "channel": "#investment-alerts",
  "text": "ğŸ’° **Rebalancing Proposal**\n\n{{DraftOrders.response}}",
  "use_blocks": true
}

// 15. GenHoldReport (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "No rebalancing needed. Generate a summary report of current holdings."
}

// 16. Answer
{
  "template": "{{DraftOrders.response}}{{GenHoldReport.response}}"
}
```

---

## 7. B2B ì˜ì—… ë¦¬ë“œ ìê²© í™•ì¸ ë° ì´ë©”ì¼ ìë™í™” (Sales SDR)

### [ì‹œë‚˜ë¦¬ì˜¤]
ì ì¬ ê³ ê°(íšŒì‚¬ëª…)ì´ ì…ë ¥ë˜ë©´ íšŒì‚¬ ì •ë³´ë¥¼ ì¡°íšŒí•˜ì—¬ ë¦¬ë“œ ì ìˆ˜ë¥¼ ë§¤ê¸°ê³ , ì ìˆ˜ì— ë”°ë¼ ê°œì¸í™”ëœ ì½œë“œ ë©”ì¼ì„ ì‘ì„±í•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> SearchCompany("íšŒì‚¬ ì •ë³´ ê²€ìƒ‰ (Tavily)")
    SearchCompany --> SearchNews("ìµœê·¼ ë‰´ìŠ¤ ê²€ìƒ‰ (Tavily)")
    SearchNews --> SearchContacts("ë‹´ë‹¹ì ê²€ìƒ‰ (Tavily)")
    
    SearchContacts --> FindCompetitors("ê²½ìŸì‚¬ ê²€ìƒ‰ (Tavily)")
    FindCompetitors --> CompareToCompetitors("ì‹œì¥ ìœ„ì¹˜ ë¶„ì„ (LLM)")
    
    CompareToCompetitors --> ScoreLead("ë¦¬ë“œ ìŠ¤ì½”ì–´ë§ (LLM)")
    ScoreLead --> CheckScore("ì ìˆ˜ í™•ì¸ (If-Else)")
    
    %% High Value Lead
    CheckScore -->|Score > 80| AnalyzePainPoints("í˜ì¸í¬ì¸íŠ¸ ë¶„ì„ (LLM)")
    AnalyzePainPoints --> DraftPersonalized("ë§ì¶¤í˜• ë©”ì¼ ì‘ì„± (LLM)")
    DraftPersonalized --> SlackSales("ì˜ì—…íŒ€ í• ë‹¹ ì•Œë¦¼ (Slack)")
    SlackSales --> SaveCRM("CRM ì €ì¥ í¬ë§· ë³€í™˜ (Assigner)")
    SaveCRM --> Answer("ê³ ê°€ì¹˜ ë¦¬ë“œ ë³´ê³ ")
    
    %% Low Value Lead
    CheckScore -->|Score <= 80| DraftGeneric("ì¼ë°˜ ì†Œê°œ ë©”ì¼ ì‘ì„± (LLM)")
    DraftGeneric --> SaveLog("ë¡œê·¸ ì €ì¥ (Assigner)")
    SaveLog --> Answer("ì¼ë°˜ ë¦¬ë“œ ì²˜ë¦¬")
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. SearchCompany (Tavily Search)
{
  "query": "{{query}} company overview headquarters",
  "topic": "general"
}

// 3. SearchNews (Tavily Search)
{
  "query": "{{query}} recent business news",
  "topic": "news"
}

// 4. SearchContacts (Tavily Search)
{
  "query": "{{query}} key decision makers CEO CTO email",
  "topic": "general"
}

// 5. FindCompetitors (Tavily Search)
{
  "query": "Competitors of {{query}}",
  "topic": "general"
}

// 6. CompareToCompetitors (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Compare {{query}} with its competitors:\n{{FindCompetitors.context}}\n\nIdentify market position (Leader/Challenger)."
}

// 7. ScoreLead (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Score this lead (0-100) based on size, news activity, and market position.\nCompany: {{SearchCompany.context}}\nNews: {{SearchNews.context}}\nPosition: {{CompareToCompetitors.response}}\n\nOutput ONLY the number."
}

// 8. CheckScore (If-Else)
{
  "cases": [
    {
      "case_id": "high_value",
      "conditions": [
        {
          "variable_selector": "ScoreLead.response",
          "comparison_operator": ">",
          "value": 80,
          "varType": "number"
        }
      ]
    }
  ]
}

// 9. AnalyzePainPoints (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Identify potential pain points for {{query}} based on recent news:\n{{SearchNews.context}}"
}

// 10. DraftPersonalized (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft a cold email to the CTO of {{query}} addressing these pain points:\n{{AnalyzePainPoints.response}}\n\nKeep it under 150 words."
}

// 11. SlackSales (Slack)
{
  "channel": "#sales-leads",
  "text": "ğŸ”¥ **High Value Lead: {{query}}**\nScore: {{ScoreLead.response}}\n\nDraft Email:\n{{DraftPersonalized.response}}",
  "use_blocks": true
}

// 12. SaveCRM (Assigner)
{
  "operations": [
    {
      "write_mode": "APPEND",
      "target_variable": "conversation.crm_leads",
      "source_variable": "query"
    }
  ]
}

// 13. DraftGeneric (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Draft a generic introduction email for {{query}}."
}

// 14. SaveLog (Assigner)
{
  "operations": [
    {
      "write_mode": "APPEND",
      "target_variable": "conversation.low_priority_logs",
      "source_variable": "query"
    }
  ]
}

// 15. Answer
{
  "template": "Lead processing complete for {{query}}.\nScore: {{ScoreLead.response}}"
}
```

---

## 8. ë²•ë¥  ê³„ì•½ì„œ ë¦¬ìŠ¤í¬ ê²€í† ê¸° (Legal Reviewer)

### [ì‹œë‚˜ë¦¬ì˜¤]
ê³„ì•½ì„œ ì´ˆì•ˆì„ ì…ë ¥ë°›ì•„ ë…ì†Œ ì¡°í•­ì„ ê²€í† í•˜ê³ , ê´€ë ¨ íŒë¡€ë¥¼ ê²€ìƒ‰í•˜ì—¬ ìˆ˜ì •ì•ˆì„ ì œì•ˆí•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> SplitClauses("ì¡°í•­ ë¶„ë¦¬ (LLM)")
    SplitClauses --> AssignClauses("ì¡°í•­ ë¦¬ìŠ¤íŠ¸ ì €ì¥ (Assigner)")
    
    %% Clause 1 Analysis
    AssignClauses --> AnalyzeC1("ì œ1ì¡° ë¶„ì„ (LLM)")
    AnalyzeC1 --> SearchPrecedent1("ê´€ë ¨ íŒë¡€ ê²€ìƒ‰ (Tavily)")
    SearchPrecedent1 --> RiskCheck1("ìœ„í—˜ë„ í‰ê°€ (If-Else)")
    
    %% Clause 2 Analysis
    RiskCheck1 --> AnalyzeC2("ì œ2ì¡° ë¶„ì„ (LLM)")
    AnalyzeC2 --> SearchPrecedent2("ê´€ë ¨ íŒë¡€ ê²€ìƒ‰ (Tavily)")
    SearchPrecedent2 --> RiskCheck2("ìœ„í—˜ë„ í‰ê°€ (If-Else)")
    
    %% Clause 3 Analysis
    RiskCheck2 --> AnalyzeC3("ì œ3ì¡° ë¶„ì„ (LLM)")
    AnalyzeC3 --> SearchPrecedent3("ê´€ë ¨ íŒë¡€ ê²€ìƒ‰ (Tavily)")
    SearchPrecedent3 --> RiskCheck3("ìœ„í—˜ë„ í‰ê°€ (If-Else)")
    
    %% Synthesis
    RiskCheck3 --> SummarizeRisks("ìœ„í—˜ ìš”ì†Œ ìš”ì•½ (LLM)")
    SummarizeRisks --> DraftAmendments("ìˆ˜ì •ì•ˆ ì‘ì„± (LLM)")
    
    DraftAmendments --> IfCritical("ì¹˜ëª…ì  ê²°í•¨? (If-Else)")
    IfCritical -->|Yes| SlackLegal("ë²•ë¬´íŒ€ í˜¸ì¶œ (Slack)")
    IfCritical -->|No| AutoFormat("ê²€í† ì„œ í¬ë§·íŒ… (LLM)")
    
    SlackLegal --> Answer
    AutoFormat --> Answer
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. SplitClauses (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Split this contract into individual clauses. Return as JSON list of strings.\nContract:\n{{query}}"
}

// 3. AssignClauses (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.clauses",
      "source_variable": "SplitClauses.response"
    }
  ]
}

// 4. AnalyzeC1 (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Analyze Clause 1 for fairness and risk:\n{{conversation.clauses[0]}}"
}

// 5. SearchPrecedent1 (Tavily Search)
{
  "query": "Legal precedents for clause: {{conversation.clauses[0]}}",
  "topic": "general"
}

// 6. RiskCheck1 (If-Else)
{
  "cases": [
    {
      "case_id": "risky_c1",
      "conditions": [{ "variable_selector": "AnalyzeC1.response", "comparison_operator": "contains", "value": "HIGH RISK" }]
    }
  ]
}

// 7. AnalyzeC2 (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Analyze Clause 2 for fairness and risk:\n{{conversation.clauses[1]}}"
}

// 8. SearchPrecedent2 (Tavily Search)
{
  "query": "Legal precedents for clause: {{conversation.clauses[1]}}",
  "topic": "general"
}

// 9. RiskCheck2 (If-Else)
{
  "cases": [
    {
      "case_id": "risky_c2",
      "conditions": [{ "variable_selector": "AnalyzeC2.response", "comparison_operator": "contains", "value": "HIGH RISK" }]
    }
  ]
}

// 10. AnalyzeC3 (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Analyze Clause 3 for fairness and risk:\n{{conversation.clauses[2]}}"
}

// 11. SearchPrecedent3 (Tavily Search)
{
  "query": "Legal precedents for clause: {{conversation.clauses[2]}}",
  "topic": "general"
}

// 12. RiskCheck3 (If-Else)
{
  "cases": [
    {
      "case_id": "risky_c3",
      "conditions": [{ "variable_selector": "AnalyzeC3.response", "comparison_operator": "contains", "value": "HIGH RISK" }]
    }
  ]
}

// 13. SummarizeRisks (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Summarize all identified risks from Clauses 1, 2, 3."
}

// 14. DraftAmendments (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft amendments for the risky clauses to protect our interests."
}

// 15. IfCritical (If-Else)
{
  "cases": [
    {
      "case_id": "critical_issues",
      "conditions": [{ "variable_selector": "SummarizeRisks.response", "comparison_operator": "contains", "value": "CRITICAL" }]
    }
  ]
}

// 16. SlackLegal (Slack)
{
  "channel": "#legal-team",
  "text": "âš–ï¸ **Contract Review Request**\n\nCritical issues found in {{query}}.\n\nRisks:\n{{SummarizeRisks.response}}",
  "use_blocks": true
}

// 17. AutoFormat (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Format the review as a clean Markdown document."
}

// 18. Answer
{
  "template": "{{AutoFormat.response}}"
}
```

---

## 9. ì†Œì…œ ë¯¸ë””ì–´ ì½˜í…ì¸  íŒ©í† ë¦¬ (Content Factory)

### [ì‹œë‚˜ë¦¬ì˜¤]
ì£¼ì œë¥¼ ì…ë ¥í•˜ë©´ LinkedIn, Twitter, Instagramìš© ì½˜í…ì¸ ë¥¼ ê°ê°ì˜ í†¤ì•¤ë§¤ë„ˆë¡œ ìƒì„±í•˜ê³  ì ì ˆí•œ í•´ì‹œíƒœê·¸ì™€ ì´ë¯¸ì§€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> TrendSearch("íŠ¸ë Œë“œ ê²€ìƒ‰ (Tavily)")
    TrendSearch --> ConceptBrainstorm("ì»¨ì…‰ ë¸Œë ˆì¸ìŠ¤í† ë° (LLM)")
    ConceptBrainstorm --> SelectBest("ìµœì  ì»¨ì…‰ ì„ ì • (LLM)")
    
    %% LinkedIn
    SelectBest --> DraftLinkedIn("LinkedIn ê¸´ ê¸€ ì‘ì„± (LLM)")
    DraftLinkedIn --> RefineBusiness("ë¹„ì¦ˆë‹ˆìŠ¤ í†¤ ë³´ì • (LLM)")
    
    %% Twitter
    SelectBest --> DraftTwitter("íŠ¸ìœ„í„° ìŠ¤ë ˆë“œ ì‘ì„± (LLM)")
    DraftTwitter --> SplitThread("ìŠ¤ë ˆë“œ ë¶„í•  (Assigner)")
    
    %% Instagram
    SelectBest --> DraftInsta("ì¸ìŠ¤íƒ€ ìº¡ì…˜ ì‘ì„± (LLM)")
    DraftInsta --> ImagePrompt("ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ (LLM)")
    ImagePrompt --> SearchRefImg("ë ˆí¼ëŸ°ìŠ¤ ì´ë¯¸ì§€ ê²€ìƒ‰ (Tavily)")
    
    %% Hashtags
    SearchRefImg --> GenHashtags("í•´ì‹œíƒœê·¸ ìƒì„± (LLM)")
    
    %% Review & Output
    GenHashtags --> ComplianceCheck("ê¸ˆì§€ì–´/ì •ì±… í™•ì¸ (LLM)")
    ComplianceCheck --> IfPolicySafe("ì •ì±… ìœ„ë°˜? (If-Else)")
    
    IfPolicySafe -->|Safe| PackContent("ì½˜í…ì¸  íŒ¨í‚¤ì§• (LLM)")
    IfPolicySafe -->|Unsafe| FixContent("ìˆ˜ì • (LLM)")
    
    FixContent --> PackContent
    PackContent --> Answer
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. TrendSearch (Tavily Search)
{
  "query": "Trending topics in {{query}}",
  "topic": "general"
}

// 3. ConceptBrainstorm (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Brainstorm 5 unique content angles for '{{query}}' based on trends:\n{{TrendSearch.context}}"
}

// 4. SelectBest (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Select the single best concept from the list that has the highest viral potential."
}

// 5. DraftLinkedIn (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft a LinkedIn post for the concept: {{SelectBest.response}}. Professional, insightful tone."
}

// 6. RefineBusiness (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Refine the LinkedIn post to be more engaging and business-oriented.\n\nPost:\n{{DraftLinkedIn.response}}"
}

// 7. DraftTwitter (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft a Twitter thread (5 tweets) for the concept: {{SelectBest.response}}. Casual, punchy tone."
}

// 8. SplitThread (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "VARIABLE",
      "target_variable": "conversation.twitter_thread",
      "source_variable": "DraftTwitter.response"
    }
  ]
}

// 9. DraftInsta (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft an Instagram caption for the concept: {{SelectBest.response}}. Fun, emoji-rich tone."
}

// 10. ImagePrompt (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Create an AI image generation prompt for this Instagram post."
}

// 11. SearchRefImg (Tavily Search)
{
  "query": "{{ImagePrompt.response}} reference image",
  "topic": "general",
  "include_images": true
}

// 12. GenHashtags (LLM)
{
  "prompt_template": "Generate 30 hashtags for Instagram based on: {{DraftInsta.response}}"
}

// 13. ComplianceCheck (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Check all generated content for policy violations (hate speech, misinformation).\n\nContent:\n{{RefineBusiness.response}}\n{{conversation.twitter_thread}}\n{{DraftInsta.response}}\n\nOutput 'SAFE' or 'UNSAFE'."
}

// 14. IfPolicySafe (If-Else)
{
  "cases": [
    {
      "case_id": "safe_content",
      "conditions": [{ "variable_selector": "ComplianceCheck.response", "comparison_operator": "contains", "value": "SAFE" }]
    }
  ]
}

// 15. FixContent (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Remove any unsafe content and rewrite."
}

// 16. PackContent (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Package all content into a JSON object:\n{\n  \"linkedin\": \"...\",\n  \"twitter\": \"...\",\n  \"instagram\": \"...\"\n}"
}

// 17. Answer
{
  "template": "Content Generation Complete!\n\n{{PackContent.response}}"
}
```

---

## 10. ì£¼ê°„ ì—…ë¬´ ìë™ ë³´ê³  ë° ì¼ì • ë¸Œë¦¬í•‘ (Weekly Assistant)

### [ì‹œë‚˜ë¦¬ì˜¤]
ìº˜ë¦°ë” ë°ì´í„°(í…ìŠ¤íŠ¸ ì…ë ¥ ê°€ì •)ì™€ ì—…ë¬´ ë¡œê·¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì£¼ê°„ ì—…ë¬´ ë³´ê³ ì„œë¥¼ ì‘ì„±í•˜ê³  ë‹¤ìŒ ì£¼ ì¤‘ìš” ì¼ì •ì„ ë¸Œë¦¬í•‘í•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> ParseInput("ì—…ë¬´/ì¼ì • ë°ì´í„° íŒŒì‹± (LLM)")
    ParseInput --> Categorize("ì—…ë¬´ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (Q-Classifier)")
    
    %% Categorization
    Categorize -->|Dev| FormatDev("ê°œë°œ ì—…ë¬´ ì •ë¦¬ (LLM)")
    Categorize -->|Meeting| FormatMeet("ë¯¸íŒ… ìš”ì•½ (LLM)")
    Categorize -->|Admin| FormatAdmin("í–‰ì • ì—…ë¬´ ì •ë¦¬ (LLM)")
    
    %% Next Week Planning
    FormatDev --> CheckDeadlines("ë§ˆê°ê¸°í•œ ì²´í¬ (LLM)")
    FormatMeet --> CheckDeadlines
    FormatAdmin --> CheckDeadlines
    
    CheckDeadlines --> Prioritize("ìš°ì„ ìˆœìœ„ ì‚°ì • (LLM)")
    Prioritize --> SearchBlockers("ì™¸ë¶€ ë¸”ë¡œì»¤ ê²€ìƒ‰ (Tavily)")
    
    SearchBlockers --> DraftWeekly("ì£¼ê°„ ë³´ê³ ì„œ ì´ˆì•ˆ (LLM)")
    DraftWeekly --> DraftBrief("ë‹¤ìŒì£¼ ë¸Œë¦¬í•‘ ì´ˆì•ˆ (LLM)")
    
    DraftBrief --> IfExec("ì„ì› ë³´ê³ ìš©? (If-Else)")
    IfExec -->|Yes| SummarizeExec("ìš”ì•½ë³¸ ìƒì„± (LLM)")
    IfExec -->|No| FullReport("ìƒì„¸ë³¸ ìƒì„± (Assigner)")
    
    SummarizeExec --> SlackReport("ë³´ê³ ì„œ ì „ì†¡ (Slack)")
    FullReport --> SlackReport
    
    SlackReport --> Answer
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. ParseInput (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Parse the raw input into a list of tasks/events.\nInput: {{query}}"
}

// 3. Categorize (Question Classifier)
{
  "classes": [
    { "id": "dev", "name": "Development" },
    { "id": "meeting", "name": "Meeting" },
    { "id": "admin", "name": "Administrative" }
  ],
  "query_template": "Classify the task type: {{ParseInput.response}}"
}

// 4. FormatDev (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Format as a development task: {{ParseInput.response}}"
}

// 5. FormatMeet (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Format as a meeting summary: {{ParseInput.response}}"
}

// 6. FormatAdmin (LLM)
{
  "model": "gpt-3.5-turbo",
  "prompt_template": "Format as an admin task: {{ParseInput.response}}"
}

// 7. CheckDeadlines (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Check if any deadlines are approaching this week based on current date."
}

// 8. Prioritize (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Assign priority (High/Medium/Low) to each task."
}

// 9. SearchBlockers (Tavily Search)
{
  "query": "External blockers for {{Prioritize.response}}",
  "topic": "general"
}

// 10. DraftWeekly (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft the Weekly Report.\nTasks: {{Prioritize.response}}\nBlockers: {{SearchBlockers.context}}"
}

// 11. DraftBrief (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Draft a verbal briefing script for next week's schedule."
}

// 12. IfExec (If-Else)
{
  "cases": [
    {
      "case_id": "exec_report",
      "conditions": [{ "variable_selector": "query", "comparison_operator": "contains", "value": "executive" }]
    }
  ]
}

// 13. SummarizeExec (LLM)
{
  "model": "gpt-4o",
  "prompt_template": "Summarize the report for an executive summary (max 3 bullet points)."
}

// 14. FullReport (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "target_variable": "conversation.final_report",
      "source_variable": "DraftWeekly.response"
    }
  ]
}

// 15. SlackReport (Slack)
{
  "channel": "#weekly-reports",
  "text": "ğŸ“… **Weekly Report**\n\n{{conversation.final_report}}{{SummarizeExec.response}}",
  "use_blocks": true
}

// 16. Answer
{
  "template": "Report Sent!\n\n{{SlackReport.message_ts}}"
}
```

---

## 11. ì¹´í…Œê³ ë¦¬ë³„ ë§ì¶¤ í†¤ ë‰´ìŠ¤ ë¸Œë¦¬í•‘ ë´‡ (Multi-Persona News Briefing)

### [ì‹œë‚˜ë¦¬ì˜¤]
IT(ì „ë¬¸ì /ê±´ì¡°í•¨), ê²½ì œ(ë¶„ì„ì /ìˆ˜ì¹˜ì¤‘ì‹¬), ë¬¸í™”(ê°ì„±ì /ì´ëª¨ì§€) ë“± 3ê°€ì§€ ì¹´í…Œê³ ë¦¬ì˜ ë‰´ìŠ¤ë¥¼ ê°ê° ìˆ˜ì§‘í•©ë‹ˆë‹¤. ê° ì¹´í…Œê³ ë¦¬ì— íŠ¹í™”ëœ í˜ë¥´ì†Œë‚˜(Persona)ë¥¼ ê°€ì§„ LLMì´ ë‰´ìŠ¤ë¥¼ ì¬ê°€ê³µí•˜ì—¬, ì„±ê²©ì´ ë‹¤ë¥¸ 3ê°œì˜ ìŠ¬ë™ ì±„ë„(#tech, #economy, #culture)ë¡œ ê°œë³„ ë°œì†¡í•˜ê³  ìµœì¢… ê²°ê³¼ë¥¼ ìš”ì•½í•©ë‹ˆë‹¤.

### [ì™€ì´ì–´í”„ë ˆì„ (Mermaid Flowchart)]

```mermaid
graph TD
    Start --> SetTopics("í† í”½ ë° í˜ë¥´ì†Œë‚˜ ì„¤ì • (Assigner)")
    
    %% Tech Branch (Professional)
    SetTopics --> SearchTech("IT ê¸°ìˆ  ë‰´ìŠ¤ ê²€ìƒ‰ (Tavily)")
    SearchTech --> SelectTech("í•µì‹¬ ê¸°ì‚¬ ì„ ì • (LLM)")
    SelectTech --> StyleTech("ì—”ì§€ë‹ˆì–´ í†¤ ë³€í™˜ (LLM)")
    StyleTech --> SlackTech("Slack ì „ì†¡ (#tech) (Slack)")
    
    %% Economy Branch (Analytical)
    SetTopics --> SearchEco("ê²½ì œ/ì¦ì‹œ ë‰´ìŠ¤ ê²€ìƒ‰ (Tavily)")
    SearchEco --> SelectEco("í•µì‹¬ ê¸°ì‚¬ ì„ ì • (LLM)")
    SelectEco --> StyleEco("ì• ë„ë¦¬ìŠ¤íŠ¸ í†¤ ë³€í™˜ (LLM)")
    StyleEco --> SlackEco("Slack ì „ì†¡ (#economy) (Slack)")
    
    %% Culture Branch (Emotional)
    SetTopics --> SearchCul("ë¬¸í™”/íŠ¸ë Œë“œ ë‰´ìŠ¤ ê²€ìƒ‰ (Tavily)")
    SearchCul --> SelectCul("í•µì‹¬ ê¸°ì‚¬ ì„ ì • (LLM)")
    SelectCul --> StyleCul("ì—ì„¸ì´/ê°ì„± í†¤ ë³€í™˜ (LLM)")
    StyleCul --> SlackCul("Slack ì „ì†¡ (#culture) (Slack)")
    
    %% Reporting
    SlackTech --> Aggregate("ë°œì†¡ ê²°ê³¼ ì·¨í•© (Assigner)")
    SlackEco --> Aggregate
    SlackCul --> Aggregate
    
    Aggregate --> GenReport("ê´€ë¦¬ì ë³´ê³ ì„œ ì‘ì„± (LLM)")
    GenReport --> Answer("ê²°ê³¼ ë³´ê³  (Answer)")
```

### [ë…¸ë“œë³„ ìƒì„¸ ì„¤ì • (Configuration)]

```json
// 1. Start
{}

// 2. SetTopics (Assigner)
{
  "operations": [
    {
      "write_mode": "SET",
      "input_type": "CONSTANT",
      "target_variable": "conversation.date",
      "value": "2025-11-22"
    },
    {
      "write_mode": "CLEAR",
      "target_variable": "conversation.log"
    }
  ]
}

// 3. SearchTech (Tavily Search)
{
  "query": "Latest Artificial Intelligence trends {{conversation.date}}",
  "topic": "news",
  "search_depth": "advanced",
  "max_results": 5,
  "include_raw_content": false,
  "include_answer": true
}

// 4. SelectTech (LLM)
{
  "model": "gpt-4o",
  "temperature": 0.5,
  "max_tokens": 2000,
  "system_prompt": "You are an editor filtering news. Select the most technically significant news items.",
  "prompt_template": "From the following search results, select top 3 most important technical news:\n{{SearchTech.context}}\n\nProvide a summary for each."
}

// 5. StyleTech (LLM)
{
  "model": "gpt-4o",
  "temperature": 0.7,
  "max_tokens": 1500,
  "system_prompt": "You are a cynical senior software engineer. Summarize the news using technical jargon, bullet points, and a dry, professional tone. No emojis.",
  "prompt_template": "Rewrite this news for developers:\n{{SelectTech.response}}"
}

// 6. SlackTech (Slack)
{
  "channel": "#tech-news",
  "text": "ğŸ›  **Tech Briefing**\n\n{{StyleTech.response}}",
  "use_blocks": true,
  "title": "Daily Tech Briefing"
}

// 7. SearchEco (Tavily Search)
{
  "query": "Global stock market and economic news {{conversation.date}}",
  "topic": "finance",
  "search_depth": "advanced",
  "max_results": 5,
  "include_answer": true
}

// 8. SelectEco (LLM)
{
  "model": "gpt-4o",
  "temperature": 0.3,
  "max_tokens": 2000,
  "system_prompt": "Select news with the highest market impact.",
  "prompt_template": "Identify top 3 financial news items from:\n{{SearchEco.context}}\n\nFocus on market indicators and major company earnings."
}

// 9. StyleEco (LLM)
{
  "model": "claude-3-5-sonnet-20240620",
  "temperature": 0.2,
  "max_tokens": 1500,
  "system_prompt": "You are a Wall Street financial analyst. Focus on numbers, percentages, and market impact. Use a serious, analytical tone.",
  "prompt_template": "Analyze this news for investors:\n{{SelectEco.response}}"
}

// 10. SlackEco (Slack)
{
  "channel": "#market-watch",
  "text": "ğŸ“Š **Market Analysis**\n\n{{StyleEco.response}}",
  "use_blocks": true,
  "title": "Market Watch Report"
}

// 11. SearchCul (Tavily Search)
{
  "query": "Pop culture trends and lifestyle news {{conversation.date}}",
  "topic": "general",
  "search_depth": "basic",
  "max_results": 5
}

// 12. SelectCul (LLM)
{
  "model": "gpt-3.5-turbo",
  "temperature": 0.8,
  "max_tokens": 2000,
  "system_prompt": "Pick the most viral and fun news stories.",
  "prompt_template": "Choose top 3 trending lifestyle news from:\n{{SearchCul.context}}"
}

// 13. StyleCul (LLM)
{
  "model": "gpt-4o",
  "temperature": 0.9,
  "max_tokens": 1500,
  "system_prompt": "You are a friendly lifestyle influencer. Use warm language, emotional storytelling, and plenty of emojis. âœ¨",
  "prompt_template": "Share this news with followers:\n{{SelectCul.response}}"
}

// 14. SlackCul (Slack)
{
  "channel": "#culture-lounge",
  "text": "â˜• **Morning Vibe**\n\n{{StyleCul.response}}",
  "use_blocks": true,
  "title": "Daily Trends âœ¨"
}

// 15. Aggregate (Assigner)
{
  "operations": [
    {
      "write_mode": "APPEND",
      "input_type": "CONSTANT",
      "target_variable": "conversation.log",
      "constant_value": "Tech news sent at {{conversation.date}}"
    },
    {
      "write_mode": "APPEND",
      "input_type": "CONSTANT",
      "target_variable": "conversation.log",
      "constant_value": "Economy news sent at {{conversation.date}}"
    },
    {
      "write_mode": "APPEND",
      "input_type": "CONSTANT",
      "target_variable": "conversation.log",
      "constant_value": "Culture news sent at {{conversation.date}}"
    }
  ]
}

// 16. GenReport (LLM)
{
  "model": "gpt-3.5-turbo",
  "temperature": 0.0,
  "prompt_template": "Generate a brief execution report based on the logs:\n{{conversation.log}}\n\nConfirm that all 3 channels received their respective briefings."
}

// 17. Answer
{
  "template": "âœ… **News Briefing Completed**\n\n{{GenReport.response}}"
}
```

---

## ê³µí†µ ì£¼ì˜ì‚¬í•­

1. **ë³€ìˆ˜ ì°¸ì¡°:** `{{NodeName.output}}` í˜•ì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ì „ ë…¸ë“œì˜ ê²°ê³¼ë¥¼ ì°¸ì¡°í•˜ì‹­ì‹œì˜¤.
2. **API í‚¤:** Tavily Search, Slack ë…¸ë“œëŠ” ë°±ì—”ë“œ í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ì„¤ì • í˜ì´ì§€ì—ì„œ API í‚¤ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.
3. **ë…¸ë“œ ID:** ìœ„ ì™€ì´ì–´í”„ë ˆì„ì— ëª…ì‹œëœ ë…¸ë“œ ID(ì˜ˆ: `TechSearch1`)ëŠ” ì‹¤ì œ ì›Œí¬í”Œë¡œìš° êµ¬ì„± ì‹œ ê³ ìœ í•´ì•¼ í•©ë‹ˆë‹¤.
4. **Assigner ëª¨ë“œ:** Assigner ë…¸ë“œëŠ” ë³€ìˆ˜ë¥¼ ë®ì–´ì“°ê¸°(`overwrite`), ì¶”ê°€(`append`) ë“±ì˜ ëª¨ë“œë¥¼ ì •í™•íˆ ì„¤ì •í•´ì•¼ ë°ì´í„° ìœ ì‹¤ì„ ë°©ì§€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**ì‘ì„±ì:** ìˆ˜ì„ ì›Œí¬í”Œë¡œìš° ì†”ë£¨ì…˜ ì•„í‚¤í…íŠ¸
**ìµœì¢… ìˆ˜ì •ì¼:** 2025-11-22

```